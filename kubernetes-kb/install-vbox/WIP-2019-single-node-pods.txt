==========================================
SINGLE NODE CLUSTER WITH PODS
==========================================

======
VMs
======
VM1
hostname = ks1
IP = 192.168.60.101

=========
ETCD
=========

----
File: /etc/environment
----
# ETCD RELATED ENVIRONMENT
REGISTRY=quay.io/coreos/etcd
# available from v3.2.5
#REGISTRY=gcr.io/etcd-development/etcd

# For each machine
#ETCD_VERSION=latest
ETCD_VERSION=v3.2.24
# Note: TOKEN can be any string
TOKEN=my-etcd-token
CLUSTER_STATE=new
CLUSTER="ks1=http://192.168.60.101:2380"
DATA_DIR=/var/lib/etcd
THIS_NAME=ks1
THIS_IP=192.168.60.101

----
File: /etc/systemd/system/etcd.service:
----
[Unit]
Description=etcd
Documentation=https://github.com/coreos
Wants=docker.service

[Service]
Type=simple
User=root
Group=root
IOSchedulingClass=2
IOSchedulingPriority=0
EnvironmentFile=/etc/environment

# START ETCD
ExecStart=/usr/bin/docker run --rm\
  --net=host \
  -p 2379:2379 \
  -p 2380:2380 \
  --volume=${DATA_DIR}:/etcd-data \
  --name etcd ${REGISTRY}:${ETCD_VERSION} \
  /usr/local/bin/etcd \
  --data-dir=/etcd-data --name ${THIS_NAME} \
  --initial-advertise-peer-urls http://${THIS_IP}:2380 --listen-peer-urls http://0.0.0.0:2380 \
  --advertise-client-urls http://${THIS_IP}:2379 --listen-client-urls http://0.0.0.0:2379 \
  --initial-cluster ${CLUSTER} \
  --initial-cluster-state ${CLUSTER_STATE} --initial-cluster-token ${TOKEN}

Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target


- NOW, START ETCD SERVICE
-- Reload the daemon configuration.
systemctl daemon-reload

-- Enable etcd to start at boot time.
systemctl enable etcd

-- Start etcd.
systemctl start etcd

-- Verify
# ps -ef| grep etcd
--> THE DOCKER COMMAND, INVOKED BY THE SERVICE
root      7702     1  0 18:33 ?        00:00:00 /usr/bin/docker run --rm --net=host -p 2379:2379 -p 2380:2380 --volume=/var/lib/etcd:/etcd-data --name etcd quay.io/coreos/etcd:v3.2.24 /usr/local/bin/etcd --data-dir=/etcd-data --name ks1 --initial-advertise-peer-urls http://192.168.60.101:2380 --listen-peer-urls http://0.0.0.0:2380 --advertise-client-urls http://192.168.60.101:2379 --listen-client-urls http://0.0.0.0:2379 --initial-cluster ks1=http://192.168.60.101:2380 --initial-cluster-state new --initial-cluster-token my-etcd-token

--> THE ETCD EXECUTABLE INSIDE CONTAINER
root      7723  7708  0 18:33 ?        00:00:00 /usr/local/bin/etcd --data-dir=/etcd-data --name ks1 --initial-advertise-peer-urls http://192.168.60.101:2380 --listen-peer-urls http://0.0.0.0:2380 --advertise-client-urls http://192.168.60.101:2379 --listen-client-urls http://0.0.0.0:2379 --initial-cluster ks1=http://192.168.60.101:2380 --initial-cluster-state new --initial-cluster-token my-etcd-token

-- Verify cluster members
# docker exec -ti etcd /bin/sh
/ # (now, this is etcd container's shell)

/ # etcdctl member list
438ee572a442fb6c: name=ks1 peerURLs=http://192.168.60.101:2380 clientURLs=http://192.168.60.101:2379 isLeader=true


=================================
CREATE CONFIG AND MANIFEST FILES
=================================

------------------------------------------
/etc/kubernetes/kubelet-config.yaml:
------------------------------------------
(taken from https://medium.com/containerum/4-ways-to-bootstrap-a-kubernetes-cluster-de0d5150a1e4)

apiVersion: v1
clusters:
- cluster:
    server: http://127.0.0.1:8080
  name: kubernetes-systemd
contexts:
- context:
    cluster: kubernetes-systemd
    user: system:node:ks1
  name: system:node:ks1@kubernetes
current-context: system:node:ks1@kubernetes
kind: Config
preferences: {}
users:
- name: system:node:ks1

------------------------------------------------------------------------------------
/etc/kubernetes/manifests/kube-apiserver.yaml:
------------------------------------------------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  annotations:
    scheduler.alpha.kubernetes.io/critical-pod: ""
  labels:
    component: kube-apiserver
    tier: control-plane
  name: kube-apiserver
  namespace: kube-system
spec:
  hostNetwork: true
  containers:
  - command:
    - kube-apiserver
    - --advertise-address=192.168.60.101
    - --insecure-bind-address=127.0.0.1
    - --bind-address=0.0.0.0
    - --etcd-servers=https://192.168.60.101:2379
    - --service-cluster-ip-range=10.96.0.0/12
    - --admission-control=NamespaceLifecycle,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota
    image: gcr.io/google_containers/kube-apiserver-amd64:v1.12.8
    name: kube-apiserver

------------------------------------------------------------------------------------
/etc/kubernetes/manifests/kube-controller-manager.yaml:
------------------------------------------------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  annotations:
    scheduler.alpha.kubernetes.io/critical-pod: ""
  labels:
    component: kube-controller-manager
    tier: control-plane
  name: kube-controller-manager
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-controller-manager
    - --cluster-name=kubernetes
    - --master=http://127.0.0.1:8080
    - --leader-elect=true
    - --cluster-cidr=10.20.0.0/16
    - --service-cluster-ip-range=10.96.0.0/12
    image: gcr.io/google_containers/kube-controller-manager-amd64:v1.12.8
    name: kube-controller-manager
  hostNetwork: true

------------------------------------------------------------------------------------
/etc/kubernetes/manifests/kube-scheduler.yaml:
------------------------------------------------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  annotations:
    scheduler.alpha.kubernetes.io/critical-pod: ""
  labels:
    component: kube-scheduler
    tier: control-plane
  name: kube-scheduler
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-scheduler
    - --master=http://127.0.0.1:8080
    - --leader-elect=true
    image: gcr.io/google_containers/kube-scheduler-amd64:v1.12.8
    name: kube-scheduler
  hostNetwork: true


----------------
Kubelet service
----------------

File: /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf:

# Note: This dropin only works with kubeadm and kubelet v1.11+
[Service]

## COMMENTED OUT BY ME
#Environment="KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf"

## COMMENTED OUT BY ME
#Environment="KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"
## ADDED BY ME
Environment="KUBELET_CONFIG_ARGS=--config=/etc/kubernetes/kubelet-config.yaml --pod-manifest-path=/etc/kubernetes/manifests"

# This is a file that "kubeadm init" and "kubeadm join" generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically
EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env
# This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use
# the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.
EnvironmentFile=-/etc/sysconfig/kubelet
ExecStart=
## ADDED THE MANIFEST FOLDER PATH BY ME (/etc/kubernetes/manifests)
ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS

- START KUBELET
# systemctl enable kubelet
# systemctl start kubelet

All containers started, except kube-apiserver - which exited with the following error:

# docker logs d5fa03e15ed9
F0730 11:08:59.338023       1 storage_decorator.go:57] Unable to create storage backend: config (&{ /registry [https://192.168.60.101:2379]    true true 1000 0xc42013a360 <nil> 5m0s 1m0s}), err (context deadline exceeded)

https://github.com/kubernetes/kubernetes/issues/72102
https://stackoverflow.com/questions/50865788/kube-apiserver-unable-to-create-storage-backend
http://dockone.io/question/4034



-- NOTES --
Installing kubelet also will install a couple of service files:
/usr/lib/systemd/system/kubelet.service
--> which references indirectly this - /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf

- STARTING IT AS IS ERRORS OUT - modify the service file as above and restart kubelet
[root@ks1 kubelet.service.d]# systemctl enable kubelet
Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /usr/lib/systemd/system/kubelet.service.

[root@ks1 kubelet.service.d]# systemctl start kubelet

[root@ks1 kubelet.service.d]# journalctl -fu kubelet
-- Logs begin at Mon 2019-07-29 18:26:16 IST. --
Jul 29 19:39:27 ks1 systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jul 29 19:39:27 ks1 kubelet[9896]: F0729 19:39:27.336390    9896 server.go:190] failed to load Kubelet config file /var/lib/kubelet/config.yaml, error failed to read kubelet config file "/var/lib/kubelet/config.yaml", error: open /var/lib/kubelet/config.yaml: no such file or directory
Jul 29 19:39:27 ks1 systemd[1]: kubelet.service: main process exited, code=exited, status=255/n/a
Jul 29 19:39:27 ks1 systemd[1]: Unit kubelet.service entered failed state.
Jul 29 19:39:27 ks1 systemd[1]: kubelet.service failed.
Jul 29 19:39:37 ks1 systemd[1]: kubelet.service holdoff time over, scheduling restart.
Jul 29 19:39:37 ks1 systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Jul 29 19:39:37 ks1 systemd[1]: Started kubelet: The Kubernetes Node Agent.
Jul 29 19:39:37 ks1 kubelet[9909]: F0729 19:39:37.511865    9909 server.go:190] failed to load Kubelet config file /var/lib/kubelet/config.yaml, error failed to read kubelet config file "/var/lib/kubelet/config.yaml", error: open /var/lib/kubelet/config.yaml: no such file or directory
Jul 29 19:39:37 ks1 systemd[1]: kubelet.service: main process exited, code=exited, status=255/n/a
Jul 29 19:39:37 ks1 systemd[1]: Unit kubelet.service entered failed state.
Jul 29 19:39:37 ks1 systemd[1]: kubelet.service failed.


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Following are some example possibilities:
/etc/systemd/system/kubelet.service:
https://github.com/kubernetes-retired/contrib/blob/master/init/systemd/kubelet.service
(reference from https://medium.com/containerum/4-ways-to-bootstrap-a-kubernetes-cluster-de0d5150a1e4)

[Unit]
Description=Kubernetes Kubelet Server
Documentation=https://kubernetes.io/docs/concepts/overview/components/#kubelet https://kubernetes.io/docs/reference/generated/kubelet/
After=docker.service
Requires=docker.service

[Service]
WorkingDirectory=/var/lib/kubelet
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/kubelet
ExecStart=/usr/bin/kubelet \
	    $KUBE_LOGTOSTDERR \
	    $KUBE_LOG_LEVEL \
	    $KUBELET_KUBECONFIG \
	    $KUBELET_ADDRESS \
	    $KUBELET_PORT \
	    $KUBELET_HOSTNAME \
	    $KUBE_ALLOW_PRIV \
	    $KUBELET_ARGS
Restart=on-failure
KillMode=process

[Install]
WantedBy=multi-user.target

~~~~
PROD OPTION:
~~~~
/etc/systemd/system/kubelet.service:

[Unit]
Description=kubelet: The Kubernetes Node Agent
Documentation=http://kubernetes.io/docs/

[Service]
ExecStart=/usr/bin/kubelet
Restart=always
StartLimitInterval=0
RestartSec=10

[Install]
WantedBy=multi-user.target

/etc/systemd/system/kubelet.service.d/10-kubeadm.conf
...
...
